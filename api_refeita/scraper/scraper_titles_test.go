package scraper_test

import (
	"api_refeita/scraper"
	"net/http"
	"testing"
)

var expectedLengths = map[int]int{
	1:   40,
	2:   40,
	3:   40,
	4:   40,
	5:   40,
	6:   40,
	7:   40,
	8:   40,
	9:   40,
	10:  40,
	11:  40,
	12:  40,
	13:  40,
	14:  40,
	15:  40,
	16:  40,
	17:  40,
	18:  40,
	19:  40,
	20:  40,
	21:  40,
	22:  40,
	23:  40,
	24:  40,
	25:  40,
	26:  40,
	27:  40,
	28:  40,
	29:  40,
	30:  40,
	31:  40,
	32:  40,
	33:  40,
	34:  40,
	35:  40,
	36:  40,
	37:  40,
	38:  40,
	39:  40,
	40:  40,
	41:  40,
	42:  40,
	43:  40,
	44:  40,
	45:  40,
	46:  40,
	47:  40,
	48:  40,
	49:  40,
	50:  40,
	51:  40,
	52:  40,
	53:  40,
	54:  40,
	55:  40,
	56:  40,
	57:  40,
	58:  40,
	59:  40,
	60:  40,
	61:  40,
	62:  40,
	63:  40,
	64:  40,
	65:  40,
	66:  40,
	67:  40,
	68:  40,
	69:  40,
	70:  40,
	71:  40,
	72:  40,
	73:  40,
	74:  40,
	75:  40,
	76:  40,
	77:  40,
	78:  40,
	79:  40,
	80:  40,
	81:  40,
	82:  40,
	83:  40,
	84:  40,
	85:  40,
	86:  40,
	87:  40,
	88:  40,
	89:  40,
	90:  40,
	91:  40,
	92:  40,
	93:  40,
	94:  40,
	95:  40,
	96:  40,
	97:  40,
	98:  40,
	99:  40,
	100: 40,
	101: 40,
	102: 40,
	103: 40,
	104: 40,
	105: 40,
	106: 40,
	107: 40,
	108: 40,
	109: 40,
	110: 40,
	111: 40,
	112: 40,
	113: 40,
	114: 40,
	115: 40,
	116: 40,
	117: 40,
	118: 40,
	119: 40,
	120: 40,
	121: 40,
	122: 40,
	123: 40,
	124: 40,
	125: 40,
	126: 40,
	127: 40,
	128: 40,
	129: 40,
	130: 40,
	131: 40,
	132: 40,
	133: 40,
	134: 40,
	135: 40,
	136: 39,
	137: 40,
	138: 40,
	139: 40,
	140: 40,
	141: 40,
	142: 40,
	143: 40,
	144: 40,
	145: 40,
	146: 40,
	147: 40,
	148: 40,
	149: 40,
	150: 40,
	151: 40,
	152: 40,
	153: 40,
	154: 40,
	155: 40,
	156: 40,
	157: 40,
	158: 40,
	159: 40,
	160: 40,
	161: 40,
	162: 40,
	163: 40,
	164: 40,
	165: 40,
	166: 40,
	167: 40,
	168: 40,
	169: 40,
	170: 40,
	171: 40,
	172: 40,
	173: 40,
	174: 40,
	175: 40,
	176: 40,
	177: 40,
	178: 40,
	179: 40,
	180: 40,
	181: 40,
	182: 40,
	183: 40,
	184: 40,
	185: 40,
	186: 40,
	187: 40,
	188: 40,
	189: 40,
	190: 40,
	191: 40,
	192: 40,
	193: 40,
	194: 40,
	195: 40,
	196: 40,
	197: 40,
	198: 40,
	199: 40,
	200: 40,
	201: 40,
	202: 40,
	203: 40,
	204: 40,
	205: 40,
	206: 40,
	207: 40,
	208: 40,
	209: 40,
	210: 40,
	211: 40,
	212: 40,
	213: 40,
	214: 40,
	215: 40,
	216: 40,
	217: 40,
	218: 40,
	219: 40,
	220: 40,
	221: 40,
	222: 40,
	223: 40,
	224: 40,
	225: 40,
	226: 40,
	227: 15,
}

func TestGetPageTitles(t *testing.T) {

	s := scraper.NewScraper("https://mangahosted.com/mangas/page/", http.Client{})
	for i := 1; i <= 227; i++ {
		result := s.GetPageTitles(i)
		for key, value := range result {
			if key == "" || value == "" {
				t.Fatal("Chaves vazias ou urls vazias não são aceitas.")
			}
		}
		expectedLength := expectedLengths[i]
		if len(result) != expectedLength {
			t.Fatalf("O valor esperado era de %d, mas o resultado foi %d.", expectedLength, len(result))
		}
	}
}

func TestGetAllTitles(t *testing.T) {
	numberTitles := 0
	for _, v := range expectedLengths {
		numberTitles += v
	}
	result := scraper.NewScraper("https://mangahosted.com/mangas/page/", http.Client{}).GetAllTitles(227)
	if len(result) != numberTitles {
		t.Fatalf("Número de mangás esperado: %d. Recebido: %d", numberTitles, len(result))
	}
}
